{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of an entire influena build for H1, H3 and IBV to include segment and genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Starting Dataset\n",
    "\n",
    "- A fasta file containing H1, H3 and IBV consensus sequences with the following delimiters `JHID_Segment#` e.g. JH1234_1\n",
    "- Metadata manually curated containing the JHID, run ID and date_sequenced (inferred for time-resolved analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate sequences with vaccine GISAID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/cat_IV23Run6toIV24Run11.fasta ../data/references.fasta > ../data/sequences.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove sequneces which are out of molecular clock bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 32 patterns loaded from file\n"
     ]
    }
   ],
   "source": [
    "!seqkit grep -f ../config/exclude.tsv -v ../data/sequences.fasta > ../data/include.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Generate fasta with type and subtype headers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "input vaccine strain headers renamed to the following format:\n",
    "- Vaccine strains (GISAID): `Isolate name_Segment number` <- this is rediculous but works for now\n",
    "  \n",
    "\n",
    "run from the flusort scripts directory for access. flusort will append fasta headers with the following information: \n",
    "- `original-seq-name|jhid|segment|type|HA_subtype|NA_subtype|genome_completeness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:cd:1: no such file or directory: scripts/flusort/scripts\n",
      "python: can't open file '/Users/elgin/Library/CloudStorage/OneDrive-JohnsHopkins/01_Pekosz_Lab/01_Project_Notebooks/Project_0_Survalience/01_Pekosz_Lab_Survallience/01_Pekosz_Lab_Seasons/2023-24/IBV_Mostafa_Analysis/07_Run6to11_Analysis_nextstrain/scripts/flusort.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "cd scripts/flusort/scripts\n",
    "\n",
    "python flusort.py \\\n",
    "    -i ../../../data/include.fasta \\\n",
    "    -o ../../../results/flusort_out\n",
    "\n",
    "cd ../../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augur Parse - generate starting metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_augur_parse():\n",
    "    command = [\n",
    "        \"augur\", \"parse\",\n",
    "        \"--sequences\", \"../results/flusort_out/fasta_with_subtype.fasta\",\n",
    "        \"--fields\", \"name\", \"jhid\", \"segment\", \"type\", \"HA_subtype\", \"NA_subtype\", \"genome_completeness\",\n",
    "        \"--output-sequences\", \"../results/sequences.fasta\",\n",
    "        \"--output-metadata\", \"../results/metadata.tsv\"\n",
    "    ]\n",
    "    \n",
    "    # Run the command and capture the result\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Print the result and indicate the status\n",
    "    if result.returncode == 0:\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"Failed to run augur parse command. Error:\")\n",
    "        print(result.stderr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_augur_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append dates to starting metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in mostafa_meta_df: Index(['jhid', 'de-id', 'sequencing_run', 'date'], dtype='object')\n",
      "Columns in metadata_df: Index(['name', 'jhid', 'segment', 'type', 'HA_subtype', 'NA_subtype',\n",
      "       'genome_completeness'],\n",
      "      dtype='object')\n",
      "Dataframes merged successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "mostafa_meta_file = '../data/IV23Run6toIV24Run11_mostafa_meta.txt'\n",
    "metadata_file = '../results/metadata.tsv'\n",
    "\n",
    "# Load the data\n",
    "mostafa_meta_df = pd.read_csv(mostafa_meta_file, sep='\\t')\n",
    "metadata_df = pd.read_csv(metadata_file, sep='\\t')\n",
    "\n",
    "# Print the columns of each dataframe to check for 'jhid'\n",
    "print(\"Columns in mostafa_meta_df:\", mostafa_meta_df.columns)\n",
    "print(\"Columns in metadata_df:\", metadata_df.columns)\n",
    "\n",
    "# Check if 'jhid' is in both dataframes\n",
    "if 'jhid' in mostafa_meta_df.columns and 'jhid' in metadata_df.columns:\n",
    "    # Merge the dataframes on 'jhid'\n",
    "    merged_df = pd.merge(metadata_df, mostafa_meta_df, on='jhid', how='left')\n",
    "\n",
    "    # Save the merged dataframe back to the metadata file\n",
    "    merged_df.to_csv(metadata_file, sep='\\t', index=False)\n",
    "\n",
    "    print(\"Dataframes merged successfully.\")\n",
    "else:\n",
    "    print(\"Error: 'jhid' column not found in one or both dataframes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sperate genomes by subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir results results/vic results/h1n1 results/h3n2 auspice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "4316 strains were dropped during filtering\n",
      "\t4316 were filtered out by the query: \"type == 'InfluenzaB'\"\n",
      "1274 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "4262 strains were dropped during filtering\n",
      "\t4262 were filtered out by the query: \"HA_subtype == 'H3'\"\n",
      "1328 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2792 strains were dropped during filtering\n",
      "\t2792 were filtered out by the query: \"HA_subtype == 'H1'\"\n",
      "2798 strains passed all filters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loop through each fasta and sort into type and subtype directories\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Base command for augur filter\n",
    "base_command = [\n",
    "    \"augur\", \"filter\",\n",
    "    \"--sequences\", \"../results/sequences.fasta\",\n",
    "    \"--metadata\", \"../results/metadata.tsv\"\n",
    "]\n",
    "\n",
    "# Queries and their respective outputs\n",
    "queries_and_outputs = [\n",
    "    (\"type == 'InfluenzaB'\", \"../results/vic/sequences.fasta\", \"../results/vic/metadata.tsv\"),\n",
    "    (\"HA_subtype == 'H3'\", \"../results/h3n2/sequences.fasta\", \"../results/h3n2/metadata.tsv\"),\n",
    "    (\"HA_subtype == 'H1'\", \"../results/h1n1/sequences.fasta\", \"../results/h1n1/metadata.tsv\")\n",
    "]\n",
    "\n",
    "# Check and create directories if they do not exist\n",
    "for _, output_sequences, output_metadata in queries_and_outputs:\n",
    "    output_dir = os.path.dirname(output_sequences)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# Run the augur filter command for each query and output\n",
    "for query, output_sequences, output_metadata in queries_and_outputs:\n",
    "    command = base_command + [\"--query\", query, \"--output-sequences\", output_sequences, \"--output-metadata\", output_metadata]\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split subtype segments\n",
    "\n",
    "Since the mostafa lab's pipline designates IBV segments 1 and 2 according to NCBI's numbering, we need to modify it so that it is congruent with the IAV number: \n",
    "- IBV NCBI Numbering: \n",
    "  - PB1 = Segment 1\n",
    "  - PB2 = Segment 2\n",
    "- IAV NCBI Numbering:\n",
    "  - PB2 = Segment 1\n",
    "  - PB1 = Segment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2465 strains were dropped during filtering\n",
      "\t2465 were filtered out by the query: \"segment == 1\"\n",
      "333 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2463 strains were dropped during filtering\n",
      "\t2463 were filtered out by the query: \"segment == 2\"\n",
      "335 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2488 strains were dropped during filtering\n",
      "\t2488 were filtered out by the query: \"segment == 3\"\n",
      "310 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2432 strains were dropped during filtering\n",
      "\t2432 were filtered out by the query: \"segment == 4\"\n",
      "366 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2438 strains were dropped during filtering\n",
      "\t2438 were filtered out by the query: \"segment == 5\"\n",
      "360 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2434 strains were dropped during filtering\n",
      "\t2434 were filtered out by the query: \"segment == 6\"\n",
      "364 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2433 strains were dropped during filtering\n",
      "\t2433 were filtered out by the query: \"segment == 7\"\n",
      "365 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2433 strains were dropped during filtering\n",
      "\t2433 were filtered out by the query: \"segment == 8\"\n",
      "365 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1164 strains were dropped during filtering\n",
      "\t1164 were filtered out by the query: \"segment == 1\"\n",
      "164 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1178 strains were dropped during filtering\n",
      "\t1178 were filtered out by the query: \"segment == 2\"\n",
      "150 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1162 strains were dropped during filtering\n",
      "\t1162 were filtered out by the query: \"segment == 3\"\n",
      "166 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1156 strains were dropped during filtering\n",
      "\t1156 were filtered out by the query: \"segment == 4\"\n",
      "172 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1160 strains were dropped during filtering\n",
      "\t1160 were filtered out by the query: \"segment == 5\"\n",
      "168 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1158 strains were dropped during filtering\n",
      "\t1158 were filtered out by the query: \"segment == 6\"\n",
      "170 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1159 strains were dropped during filtering\n",
      "\t1159 were filtered out by the query: \"segment == 7\"\n",
      "169 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1159 strains were dropped during filtering\n",
      "\t1159 were filtered out by the query: \"segment == 8\"\n",
      "169 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1129 strains were dropped during filtering\n",
      "\t1129 were filtered out by the query: \"segment == 1\"\n",
      "145 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1108 strains were dropped during filtering\n",
      "\t1108 were filtered out by the query: \"segment == 2\"\n",
      "166 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1147 strains were dropped during filtering\n",
      "\t1147 were filtered out by the query: \"segment == 3\"\n",
      "127 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1117 strains were dropped during filtering\n",
      "\t1117 were filtered out by the query: \"segment == 4\"\n",
      "157 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1094 strains were dropped during filtering\n",
      "\t1094 were filtered out by the query: \"segment == 5\"\n",
      "180 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1119 strains were dropped during filtering\n",
      "\t1119 were filtered out by the query: \"segment == 6\"\n",
      "155 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1106 strains were dropped during filtering\n",
      "\t1106 were filtered out by the query: \"segment == 7\"\n",
      "168 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1098 strains were dropped during filtering\n",
      "\t1098 were filtered out by the query: \"segment == 8\"\n",
      "176 strains passed all filters\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Subtypes and their respective directories\n",
    "subtypes = {\n",
    "    \"h1n1\": \"../results/h1n1\",\n",
    "    \"h3n2\": \"../results/h3n2\",\n",
    "    \"vic\": \"../results/vic\"\n",
    "}\n",
    "\n",
    "# Segment names mapping with letter annotations for h1n1 and h3n2\n",
    "segment_names_h1n1_h3n2 = {\n",
    "    \"1\": \"pb2\",\n",
    "    \"2\": \"pb1\",\n",
    "    \"3\": \"pa\",\n",
    "    \"4\": \"ha\",\n",
    "    \"5\": \"np\",\n",
    "    \"6\": \"na\",\n",
    "    \"7\": \"mp\",\n",
    "    \"8\": \"ns\"\n",
    "}\n",
    "\n",
    "# Segment names mapping with letter annotations for vic\n",
    "segment_names_vic = {\n",
    "    \"1\": \"pb1\",\n",
    "    \"2\": \"pb2\",\n",
    "    \"3\": \"pa\",\n",
    "    \"4\": \"ha\",\n",
    "    \"5\": \"np\",\n",
    "    \"6\": \"na\",\n",
    "    \"7\": \"mp\",\n",
    "    \"8\": \"ns\"\n",
    "}\n",
    "\n",
    "def strip_segment_number(fasta_file):\n",
    "    with open(fasta_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    with open(fasta_file, 'w') as file:\n",
    "        for line in lines:\n",
    "            if line.startswith('>'):\n",
    "                line = line.split('_')[0] + '\\n'\n",
    "            file.write(line)\n",
    "\n",
    "def modify_metadata(metadata_file):\n",
    "    with open(metadata_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    header = lines[0].strip().split('\\t')\n",
    "    name_index = header.index('name')\n",
    "    jhid_index = header.index('jhid')\n",
    "    \n",
    "    # Create new header with 'jhid' renamed to 'name' and 'name' column removed\n",
    "    new_header = header[:name_index] + header[name_index+1:jhid_index] + ['name'] + header[jhid_index+1:]\n",
    "    \n",
    "    with open(metadata_file, 'w') as file:\n",
    "        file.write('\\t'.join(new_header) + '\\n')\n",
    "        for line in lines[1:]:\n",
    "            columns = line.strip().split('\\t')\n",
    "            new_columns = columns[:name_index] + columns[name_index+1:jhid_index] + [columns[jhid_index]] + columns[jhid_index+1:]\n",
    "            file.write('\\t'.join(new_columns) + '\\n')\n",
    "\n",
    "# Loop through each subtype\n",
    "for subtype, subtype_dir in subtypes.items():\n",
    "    if subtype in [\"h1n1\", \"h3n2\"]:\n",
    "        segment_names = segment_names_h1n1_h3n2\n",
    "    else:  # vic\n",
    "        segment_names = segment_names_vic\n",
    "\n",
    "    for segment_num, segment_name in segment_names.items():\n",
    "        # Create a new folder for each segment within the subtype directory\n",
    "        segment_folder = os.path.join(subtype_dir, segment_name)\n",
    "        if not os.path.exists(segment_folder):\n",
    "            os.makedirs(segment_folder)\n",
    "\n",
    "        # Construct the command for augur filter\n",
    "        command = [\n",
    "            \"augur\", \"filter\",\n",
    "            \"--sequences\", f\"{subtype_dir}/sequences.fasta\",\n",
    "            \"--metadata\", f\"{subtype_dir}/metadata.tsv\",\n",
    "            \"--query\", f\"segment == {segment_num}\",\n",
    "            \"--output-sequences\", f\"{segment_folder}/sequences.fasta\",\n",
    "            \"--output-metadata\", f\"{segment_folder}/metadata.tsv\"\n",
    "        ]\n",
    "\n",
    "        # Run augur filter command\n",
    "        subprocess.run(command)\n",
    "\n",
    "        # Strip the segment number from the fasta headers\n",
    "        strip_segment_number(f\"{segment_folder}/sequences.fasta\")\n",
    "\n",
    "        # Modify the metadata file\n",
    "        modify_metadata(f\"{segment_folder}/metadata.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# running nextclade on each of the 8 segments provided \n",
    "\n",
    "Only need to download datasets once. Manually rename the downloaded h1n1pdm09 and h3n2 datasets to simplified segment names: `ha` and `na`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "# download nextclade datasets\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Define datasets for h3n2 and h1n1pdm\n",
    "h3n2_datasets = [\n",
    "    \"flu_h3n2_ha\",\n",
    "    \"flu_h3n2_na\",\n",
    "    \"nextstrain/flu/h3n2/pb2\",\n",
    "    \"nextstrain/flu/h3n2/pb1\",\n",
    "    \"nextstrain/flu/h3n2/pa\",\n",
    "    \"nextstrain/flu/h3n2/np\",\n",
    "    \"nextstrain/flu/h3n2/mp\",\n",
    "    \"nextstrain/flu/h3n2/ns\"\n",
    "]\n",
    "\n",
    "h1n1_datasets = [\n",
    "    \"flu_h1n1pdm_ha\",\n",
    "    \"flu_h1n1pdm_na\",\n",
    "    \"nextstrain/flu/h1n1pdm/pb2\",\n",
    "    \"nextstrain/flu/h1n1pdm/pb1\",\n",
    "    \"nextstrain/flu/h1n1pdm/pa\",\n",
    "    \"nextstrain/flu/h1n1pdm/np\",\n",
    "    \"nextstrain/flu/h1n1pdm/mp\",\n",
    "    \"nextstrain/flu/h1n1pdm/ns\"\n",
    "]\n",
    "\n",
    "# Function to execute nextclade command\n",
    "def fetch_dataset(dataset, output_dir):\n",
    "    subprocess.run([\"nextclade\", \"dataset\", \"get\", \"-n\", dataset, \"-o\", output_dir])\n",
    "\n",
    "# Fetch and organize h3n2 datasets\n",
    "for dataset in h3n2_datasets:\n",
    "    output_dir = f\"../nextclade/flu/h3n2/{dataset.split('/')[-1]}\"\n",
    "    fetch_dataset(dataset, output_dir)\n",
    "\n",
    "# Fetch and organize h1n1pdm datasets\n",
    "for dataset in h1n1_datasets:\n",
    "    output_dir = f\"../nextclade/flu/h1n1pdm/{dataset.split('/')[-1]}\"\n",
    "    fetch_dataset(dataset, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign clades with nextclade.\n",
    "\n",
    "We'll run nextclade to assign clades for HA segments and assign quality metrics for the remaining 7 segments. Output to each 'results/{subtype}' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def run_nextclade(subtype, segment):\n",
    "    input_dir = f\"../nextclade/flu/{subtype}/{segment}\"\n",
    "    output_dir = f\"../results/{subtype}/{segment}\"\n",
    "    fasta_file = f\"{output_dir}/sequences.fasta\"\n",
    "    \n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run the nextclade command\n",
    "    subprocess.run([\"nextclade\", \"run\", \"-D\", input_dir, \"-O\", output_dir, fasta_file])\n",
    "    \n",
    "    # Strip the seqName suffix in the nextstrain.tsv file\n",
    "    nextstrain_file = f\"{output_dir}/nextclade.tsv\"\n",
    "    strip_seqName_suffix(nextstrain_file)\n",
    "\n",
    "def strip_seqName_suffix(nextstrain_file):\n",
    "    with open(nextstrain_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    header = lines[0].strip().split('\\t')\n",
    "    seqName_index = header.index('seqName')\n",
    "\n",
    "    with open(nextstrain_file, 'w') as file:\n",
    "        file.write(lines[0])\n",
    "        for line in lines[1:]:\n",
    "            columns = line.strip().split('\\t')\n",
    "            columns[seqName_index] = columns[seqName_index].split('_')[0]\n",
    "            file.write('\\t'.join(columns) + '\\n')\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        run_nextclade(subtype, segment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append HA clade to metadata \n",
    "I want the clade and subclade columns from the  `results/{subtype}/ha/nextclade.tsv` to be append to each segment's metadata table located at `results/{subtype}/{segment}/metadata.tsv joining by the \"seqName\" column in the nextclade.tsv table and the \"name\" column in the metadata.tsv column\n",
    "\n",
    "2 columns to be made to each meatadata.tsv table\n",
    "- clade\n",
    "- subclade\n",
    "\n",
    "\n",
    "Finally, each segment's metadata file will have ha clade and subclade calls as a trait layer in the build as well as quality data for pre-build filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: This can only be run once as further joins do not append.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def append_clade_info(subtype, segment):\n",
    "    ha_nextclade_file = f\"../results/{subtype}/ha/nextclade.tsv\"\n",
    "    segment_metadata_file = f\"../results/{subtype}/{segment}/metadata.tsv\"\n",
    "\n",
    "    # Load the nextclade data, selecting only 'seqName', 'clade', and 'subclade' columns\n",
    "    nextclade_df = pd.read_csv(ha_nextclade_file, sep='\\t', usecols=['seqName', 'clade', 'subclade'])\n",
    "\n",
    "    # Check if required columns exist in nextclade.tsv\n",
    "    required_columns = ['seqName', 'clade', 'subclade']\n",
    "    for col in required_columns:\n",
    "        if col not in nextclade_df.columns:\n",
    "            print(f\"Error: Required column '{col}' not found in {ha_nextclade_file}\")\n",
    "            return\n",
    "\n",
    "    # Load the segment metadata\n",
    "    metadata_df = pd.read_csv(segment_metadata_file, sep='\\t')\n",
    "\n",
    "    # Merge the dataframes on 'seqName' and 'name'\n",
    "    merged_df = pd.merge(metadata_df, nextclade_df, left_on='name', right_on='seqName', how='left')\n",
    "\n",
    "    # Debugging print to check merge output\n",
    "    print(f\"Merged dataframe for {subtype}/{segment}:\")\n",
    "    print(merged_df.head())\n",
    "\n",
    "    # Check if merge was successful\n",
    "    if merged_df.empty:\n",
    "        print(f\"No matching data found for {subtype}/{segment}\")\n",
    "        return\n",
    "\n",
    "    # Update or add the 'clade' and 'subclade' columns in metadata_df\n",
    "    metadata_df['clade'] = merged_df['clade']\n",
    "    metadata_df['subclade'] = merged_df['subclade']\n",
    "\n",
    "    # Save the updated metadata\n",
    "    metadata_df.to_csv(segment_metadata_file, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"Clade information successfully appended to {subtype}/{segment}\")\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        append_clade_info(subtype, segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge quality metrics for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clade and quality information successfully appended to h3n2/pb2\n",
      "Clade and quality information successfully appended to h3n2/pb1\n",
      "Clade and quality information successfully appended to h3n2/pa\n",
      "Clade and quality information successfully appended to h3n2/ha\n",
      "Clade and quality information successfully appended to h3n2/np\n",
      "Clade and quality information successfully appended to h3n2/na\n",
      "Clade and quality information successfully appended to h3n2/mp\n",
      "Clade and quality information successfully appended to h3n2/ns\n",
      "Clade and quality information successfully appended to h1n1/pb2\n",
      "Clade and quality information successfully appended to h1n1/pb1\n",
      "Clade and quality information successfully appended to h1n1/pa\n",
      "Clade and quality information successfully appended to h1n1/ha\n",
      "Clade and quality information successfully appended to h1n1/np\n",
      "Clade and quality information successfully appended to h1n1/na\n",
      "Clade and quality information successfully appended to h1n1/mp\n",
      "Clade and quality information successfully appended to h1n1/ns\n",
      "Clade and quality information successfully appended to vic/pb2\n",
      "Clade and quality information successfully appended to vic/pb1\n",
      "Clade and quality information successfully appended to vic/pa\n",
      "Clade and quality information successfully appended to vic/ha\n",
      "Clade and quality information successfully appended to vic/np\n",
      "Clade and quality information successfully appended to vic/na\n",
      "Clade and quality information successfully appended to vic/mp\n",
      "Clade and quality information successfully appended to vic/ns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def append_clade_and_quality_info(subtype, segment):\n",
    "    segment_nextclade_file = f\"../results/{subtype}/{segment}/nextclade.tsv\"\n",
    "    segment_metadata_file = f\"../results/{subtype}/{segment}/metadata.tsv\"\n",
    "\n",
    "    # Load the nextclade data, selecting required columns\n",
    "    nextclade_df = pd.read_csv(segment_nextclade_file, sep='\\t', usecols=['seqName', 'qc.overallScore', 'qc.overallStatus', 'coverage'])\n",
    "\n",
    "    # Check if required columns exist in nextclade.tsv\n",
    "    required_columns = ['seqName', 'qc.overallScore', 'qc.overallStatus', 'coverage']\n",
    "    for col in required_columns:\n",
    "        if col not in nextclade_df.columns:\n",
    "            print(f\"Error: Required column '{col}' not found in {segment_nextclade_file}\")\n",
    "            return\n",
    "\n",
    "    # Load the segment metadata\n",
    "    metadata_df = pd.read_csv(segment_metadata_file, sep='\\t')\n",
    "\n",
    "    # Merge the dataframes on 'seqName' and 'name'\n",
    "    merged_df = pd.merge(metadata_df, nextclade_df, left_on='name', right_on='seqName', how='left')\n",
    "\n",
    "    # Check if merge was successful\n",
    "    if merged_df.empty:\n",
    "        print(f\"No matching data found for {subtype}/{segment}\")\n",
    "        return\n",
    "\n",
    "    # Update or add the columns in metadata_df\n",
    "    for col in ['qc.overallScore', 'qc.overallStatus', 'coverage']:\n",
    "        metadata_df[col] = merged_df[col]\n",
    "\n",
    "    # Drop the 'seqName' column after merging, if it exists\n",
    "    if 'seqName' in metadata_df.columns:\n",
    "        metadata_df = metadata_df.drop(columns=['seqName'])\n",
    "\n",
    "    # Save the updated metadata\n",
    "    metadata_df.to_csv(segment_metadata_file, sep='\\t', index=False)\n",
    "\n",
    "    print(f\"Clade and quality information successfully appended to {subtype}/{segment}\")\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        append_clade_and_quality_info(subtype, segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin nextstrain build for all 8 segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this build will use size-based filtering as a crude genome quality metric assuming all consensus sequences are of high quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add the vaccine strains to each build ✅\n",
    "- Append HA clade to segment metadata ✅\n",
    "- Append QC to segment metadata ✅\n",
    "- Append dates to segment metadata ⚠️ <- you can join this early after the first parse from flusort output. \n",
    "\n",
    "nextstrain construction:\n",
    "\n",
    "1.  filter quality \n",
    "    -  coverage \n",
    "    -  qc.overallStatus - good or mediocre? likely just good\n",
    "2. index \n",
    "3. align\n",
    "4. build tree\n",
    "5. refine tree\n",
    "6. annotate\n",
    "7. infer ancestral sequences\n",
    "8. translate to amino acid mutations\n",
    "9. calculate tip frequencies\n",
    "10. export genome builds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "12 strains were dropped during filtering\n",
      "\t12 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "152 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "145 strains were dropped during filtering\n",
      "\t145 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "5 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "16 strains were dropped during filtering\n",
      "\t16 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "150 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2 strains were dropped during filtering\n",
      "\t2 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "170 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "0 strains were dropped during filtering\n",
      "168 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "48 strains were dropped during filtering\n",
      "\t48 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "122 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "0 strains were dropped during filtering\n",
      "169 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "0 strains were dropped during filtering\n",
      "169 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "29 strains were dropped during filtering\n",
      "\t29 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "304 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "56 strains were dropped during filtering\n",
      "\t53 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "\t3 were dropped because they were shorter than the minimum length of 2000bp when only counting standard nucleotide characters A, C, G, or T (case-insensitive)\n",
      "279 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "56 strains were dropped during filtering\n",
      "\t52 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "\t4 were dropped because they were shorter than the minimum length of 1800bp when only counting standard nucleotide characters A, C, G, or T (case-insensitive)\n",
      "254 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "124 strains were dropped during filtering\n",
      "\t124 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "242 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "0 strains were dropped during filtering\n",
      "360 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "0 strains were dropped during filtering\n",
      "364 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "4 strains were dropped during filtering\n",
      "\t4 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "361 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "1 strain was dropped during filtering\n",
      "\t1 was filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "364 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "35 strains were dropped during filtering\n",
      "\t31 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "\t4 were dropped because they were shorter than the minimum length of 2000bp when only counting standard nucleotide characters A, C, G, or T (case-insensitive)\n",
      "131 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "34 strains were dropped during filtering\n",
      "\t28 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "\t6 were dropped because they were shorter than the minimum length of 2000bp when only counting standard nucleotide characters A, C, G, or T (case-insensitive)\n",
      "111 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "25 strains were dropped during filtering\n",
      "\t24 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "\t1 was dropped because it was shorter than the minimum length of 1800bp when only counting standard nucleotide characters A, C, G, or T (case-insensitive)\n",
      "102 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "17 strains were dropped during filtering\n",
      "\t17 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "140 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "40 strains were dropped during filtering\n",
      "\t40 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "140 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "21 strains were dropped during filtering\n",
      "\t21 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "134 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "14 strains were dropped during filtering\n",
      "\t14 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "154 strains passed all filters\n",
      "Note: You did not provide a sequence index, so Augur will generate one. You can generate your own index ahead of time with `augur index` and pass it with `augur filter --sequence-index`.\n",
      "2 strains were dropped during filtering\n",
      "\t2 were filtered out by the query: \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\"\n",
      "174 strains passed all filters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "# Define the minimum lengths for each segment\n",
    "min_lengths = {\n",
    "    \"pb2\": 2000,\n",
    "    \"pb1\": 2000,\n",
    "    \"pa\": 1800,\n",
    "    \"ha\": 1400,\n",
    "    \"np\": 1200,\n",
    "    \"na\": 1200,\n",
    "    \"mp\": 700,\n",
    "    \"ns\": 700\n",
    "}\n",
    "\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        sequences_file = f\"../results/{subtype}/{segment}/sequences.fasta\"\n",
    "        metadata_file = f\"../results/{subtype}/{segment}/metadata.tsv\"\n",
    "        output_sequences_file = f\"../results/{subtype}/{segment}/filtered.fasta\"\n",
    "        output_metadata_file = f\"../results/{subtype}/{segment}/filtered.tsv\"\n",
    "\n",
    "        min_length = min_lengths.get(segment, 0)  # Default to 0 if segment not found\n",
    "\n",
    "        command = [\n",
    "            \"augur\", \"filter\",\n",
    "            \"--sequences\", sequences_file,\n",
    "            \"--metadata\", metadata_file,\n",
    "            \"--query\", \"(coverage >= 0.9) & (`qc.overallStatus` == 'good')\",  # Add qc_overallStatus == 'mediocre' if needed\n",
    "            \"--min-length\", str(min_length),\n",
    "            \"--output-sequences\", output_sequences_file,\n",
    "            \"--output-metadata\", output_metadata_file\n",
    "        ]\n",
    "\n",
    "        subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def index_sequences(subtype, segment):\n",
    "    sequences_file = f\"../results/{subtype}/{segment}/filtered.fasta\"\n",
    "    output_index_file = f\"../results/{subtype}/{segment}/filtered.index.tsv\"\n",
    "    \n",
    "    # Construct the augur index command\n",
    "    command = [\n",
    "        \"augur\", \"index\",\n",
    "        \"--sequences\", sequences_file,\n",
    "        \"--output\", output_index_file\n",
    "    ]\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(command)\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        index_sequences(subtype, segment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/pb2/aligned.fasta.to_align.fasta 1> ../results/h3n2/pb2/aligned.fasta 2> ../results/h3n2/pb2/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_007373.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/pb1/aligned.fasta.to_align.fasta 1> ../results/h3n2/pb1/aligned.fasta 2> ../results/h3n2/pb1/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_007372.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/pa/aligned.fasta.to_align.fasta 1> ../results/h3n2/pa/aligned.fasta 2> ../results/h3n2/pa/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "36bp insertion at ref position 2024\n",
      "\tTAGATTTCCATTTCATCAATGAACAAGGCGAATCAA: JH24967\n",
      "Trimmed gaps in NC_007371.1 from the alignment\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/ha/aligned.fasta.to_align.fasta 1> ../results/h3n2/ha/aligned.fasta 2> ../results/h3n2/ha/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "1bp insertion at ref position 48\n",
      "\tC: JH24116, JH24257\n",
      "Trimmed gaps in OQ718999.1 from the alignment\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/np/aligned.fasta.to_align.fasta 1> ../results/h3n2/np/aligned.fasta 2> ../results/h3n2/np/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_007369.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/na/aligned.fasta.to_align.fasta 1> ../results/h3n2/na/aligned.fasta 2> ../results/h3n2/na/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, OQ718998.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/mp/aligned.fasta.to_align.fasta 1> ../results/h3n2/mp/aligned.fasta 2> ../results/h3n2/mp/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_007367.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h3n2/ns/aligned.fasta.to_align.fasta 1> ../results/h3n2/ns/aligned.fasta 2> ../results/h3n2/ns/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_007370.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/pb2/aligned.fasta.to_align.fasta 1> ../results/h1n1/pb2/aligned.fasta 2> ../results/h1n1/pb2/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_026438.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/pb1/aligned.fasta.to_align.fasta 1> ../results/h1n1/pb1/aligned.fasta 2> ../results/h1n1/pb1/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_026435.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/pa/aligned.fasta.to_align.fasta 1> ../results/h1n1/pa/aligned.fasta 2> ../results/h1n1/pa/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_026437.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/ha/aligned.fasta.to_align.fasta 1> ../results/h1n1/ha/aligned.fasta 2> ../results/h1n1/ha/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, CY121680.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/np/aligned.fasta.to_align.fasta 1> ../results/h1n1/np/aligned.fasta 2> ../results/h1n1/np/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_026436.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/na/aligned.fasta.to_align.fasta 1> ../results/h1n1/na/aligned.fasta 2> ../results/h1n1/na/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, MW626056.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/mp/aligned.fasta.to_align.fasta 1> ../results/h1n1/mp/aligned.fasta 2> ../results/h1n1/mp/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_026431.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/h1n1/ns/aligned.fasta.to_align.fasta 1> ../results/h1n1/ns/aligned.fasta 2> ../results/h1n1/ns/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, NC_026432.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/pb2/aligned.fasta.to_align.fasta 1> ../results/vic/pb2/aligned.fasta 2> ../results/vic/pb2/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, KC866604.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/pb1/aligned.fasta.to_align.fasta 1> ../results/vic/pb1/aligned.fasta 2> ../results/vic/pb1/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "6bp insertion at ref position 229\n",
      "\tGAGGCT: JH24827\n",
      "Trimmed gaps in KC866603.1 from the alignment\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/pa/aligned.fasta.to_align.fasta 1> ../results/vic/pa/aligned.fasta 2> ../results/vic/pa/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "3bp insertion at ref position 1148\n",
      "\tAGA: JH241024\n",
      "Trimmed gaps in KC866602.1 from the alignment\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/ha/aligned.fasta.to_align.fasta 1> ../results/vic/ha/aligned.fasta 2> ../results/vic/ha/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, KX058884.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/np/aligned.fasta.to_align.fasta 1> ../results/vic/np/aligned.fasta 2> ../results/vic/np/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, KC866605.1)\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/na/aligned.fasta.to_align.fasta 1> ../results/vic/na/aligned.fasta 2> ../results/vic/na/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "39bp insertion at ref position 0\n",
      "\tATGAACA: JH23900, JH23855, JH241041, JH24618, JH24661, JH24776, JH24174, JH24276, JH24816, JH24805, JH24902, JH241028, JH24616, JH24828, JH24843, JH24822, JH24793, JH24784, JH24284, JH24663, JH24398, JH24945, JH24949, JH24561, JH24940, B/Austria/1359417/2021, JH23903, JH23902, JH23665, JH241030, JH24278, JH24819, JH241042, JH2410, JH24772, JH241002, JH23897, JH24275, JH24281, JH24623, JH24811, JH23664, JH23666, JH23680, JH23681, JH23682, JH2455, JH23663, JH2430, JH23679, JH24794, JH24554, JH24283, JH24909, JH24920, JH241037, JH241019, JH241032, JH241005, JH241017, JH241047, JH241026, JH241046, JH241024, JH24547, JH24559, JH24560, JH24621, JH24664, JH24842, JH24826, JH24798, JH24837, JH24904, JH241031, JH241038, JH241033, JH241045, JH241014, JH241035, JH24562, JH24660, JH24812, JH24764, JH241021, JH241025, JH24906, JH24914, JH24282, JH24911, JH241001, JH241027, JH24402, JH24813, JH24814, JH24919, JH24912, JH241004, JH241018, JH241039, JH24835, JH241034, JH241013, JH24177, JH24563, JH24824, JH24783, JH24820, JH241012, JH24809, JH24617, JH24548, JH24659, JH24808, JH24769, JH241007, JH241016, JH24999, JH241023, JH241020, JH24557, JH24658, JH24551, JH24619, JH24827, JH2440, JH24543, JH23898, JH24907, JH241049, JH241043, JH24550\n",
      "\tATAGACA: JH2454\n",
      "\tATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACA: B/Baltimore/0546/2023\n",
      "88bp insertion at ref position 1401\n",
      "\tTGGGGGAGTGGTTAAGTCTGTTCTAAACCCTTTGTTCCTATTTTATTTGAACAATTGTCCTTACTAAACTTAATTGTTTCTGAAAAAT: B/Baltimore/0546/2023\n",
      "Trimmed gaps in CY073894.1 from the alignment\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/mp/aligned.fasta.to_align.fasta 1> ../results/vic/mp/aligned.fasta 2> ../results/vic/mp/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "5bp insertion at ref position 0\n",
      "\tTCTTA: B/Baltimore/0546/2023\n",
      "2bp insertion at ref position 1147\n",
      "\tAA: B/Baltimore/0546/2023\n",
      "Trimmed gaps in CY115152.1 from the alignment\n",
      "\n",
      "using mafft to align via:\n",
      "\tmafft --reorder --anysymbol --nomemsave --adjustdirection --thread 8 ../results/vic/ns/aligned.fasta.to_align.fasta 1> ../results/vic/ns/aligned.fasta 2> ../results/vic/ns/aligned.fasta.log \n",
      "\n",
      "\tKatoh et al, Nucleic Acid Research, vol 30, issue 14\n",
      "\thttps://doi.org/10.1093%2Fnar%2Fgkf436\n",
      "\n",
      "No gaps in alignment to trim (with respect to the reference, KC866606.1)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def align_sequences(subtype, segment):\n",
    "    sequences_file = f\"../results/{subtype}/{segment}/filtered.fasta\"\n",
    "    reference_file = f\"../config/{subtype}/reference_{segment}.gb\"\n",
    "    output_aligned_file = f\"../results/{subtype}/{segment}/aligned.fasta\"\n",
    "    \n",
    "    # Construct the augur align command\n",
    "    command = [\n",
    "        \"augur\", \"align\",\n",
    "        \"--sequences\", sequences_file,\n",
    "        \"--nthreads\", \"8\",\n",
    "        \"--reference-sequence\", reference_file,\n",
    "        \"--remove-reference\",\n",
    "        \"--output\", output_aligned_file,\n",
    "        \"--fill-gaps\"\n",
    "    ]\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(command)\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        align_sequences(subtype, segment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alignment for pb2 in subtype h3n2...\n",
      "Successfully aligned pb2 for subtype h3n2. Tree saved to ../results/h3n2/pb2/tree_raw.nwk\n",
      "Processing alignment for pb1 in subtype h3n2...\n",
      "Successfully aligned pb1 for subtype h3n2. Tree saved to ../results/h3n2/pb1/tree_raw.nwk\n",
      "Processing alignment for pa in subtype h3n2...\n",
      "Successfully aligned pa for subtype h3n2. Tree saved to ../results/h3n2/pa/tree_raw.nwk\n",
      "Processing alignment for ha in subtype h3n2...\n",
      "Successfully aligned ha for subtype h3n2. Tree saved to ../results/h3n2/ha/tree_raw.nwk\n",
      "Processing alignment for np in subtype h3n2...\n",
      "Successfully aligned np for subtype h3n2. Tree saved to ../results/h3n2/np/tree_raw.nwk\n",
      "Processing alignment for na in subtype h3n2...\n",
      "Successfully aligned na for subtype h3n2. Tree saved to ../results/h3n2/na/tree_raw.nwk\n",
      "Processing alignment for mp in subtype h3n2...\n",
      "Successfully aligned mp for subtype h3n2. Tree saved to ../results/h3n2/mp/tree_raw.nwk\n",
      "Processing alignment for ns in subtype h3n2...\n",
      "Successfully aligned ns for subtype h3n2. Tree saved to ../results/h3n2/ns/tree_raw.nwk\n",
      "Processing alignment for pb2 in subtype h1n1...\n",
      "Successfully aligned pb2 for subtype h1n1. Tree saved to ../results/h1n1/pb2/tree_raw.nwk\n",
      "Processing alignment for pb1 in subtype h1n1...\n",
      "Successfully aligned pb1 for subtype h1n1. Tree saved to ../results/h1n1/pb1/tree_raw.nwk\n",
      "Processing alignment for pa in subtype h1n1...\n",
      "Successfully aligned pa for subtype h1n1. Tree saved to ../results/h1n1/pa/tree_raw.nwk\n",
      "Processing alignment for ha in subtype h1n1...\n",
      "Successfully aligned ha for subtype h1n1. Tree saved to ../results/h1n1/ha/tree_raw.nwk\n",
      "Processing alignment for np in subtype h1n1...\n",
      "Successfully aligned np for subtype h1n1. Tree saved to ../results/h1n1/np/tree_raw.nwk\n",
      "Processing alignment for na in subtype h1n1...\n",
      "Successfully aligned na for subtype h1n1. Tree saved to ../results/h1n1/na/tree_raw.nwk\n",
      "Processing alignment for mp in subtype h1n1...\n",
      "Successfully aligned mp for subtype h1n1. Tree saved to ../results/h1n1/mp/tree_raw.nwk\n",
      "Processing alignment for ns in subtype h1n1...\n",
      "Successfully aligned ns for subtype h1n1. Tree saved to ../results/h1n1/ns/tree_raw.nwk\n",
      "Processing alignment for pb2 in subtype vic...\n",
      "Successfully aligned pb2 for subtype vic. Tree saved to ../results/vic/pb2/tree_raw.nwk\n",
      "Processing alignment for pb1 in subtype vic...\n",
      "Successfully aligned pb1 for subtype vic. Tree saved to ../results/vic/pb1/tree_raw.nwk\n",
      "Processing alignment for pa in subtype vic...\n",
      "Successfully aligned pa for subtype vic. Tree saved to ../results/vic/pa/tree_raw.nwk\n",
      "Processing alignment for ha in subtype vic...\n",
      "Successfully aligned ha for subtype vic. Tree saved to ../results/vic/ha/tree_raw.nwk\n",
      "Processing alignment for np in subtype vic...\n",
      "Successfully aligned np for subtype vic. Tree saved to ../results/vic/np/tree_raw.nwk\n",
      "Processing alignment for na in subtype vic...\n",
      "Successfully aligned na for subtype vic. Tree saved to ../results/vic/na/tree_raw.nwk\n",
      "Processing alignment for mp in subtype vic...\n",
      "Successfully aligned mp for subtype vic. Tree saved to ../results/vic/mp/tree_raw.nwk\n",
      "Processing alignment for ns in subtype vic...\n",
      "Successfully aligned ns for subtype vic. Tree saved to ../results/vic/ns/tree_raw.nwk\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def build_raw_tree(subtype, segment):\n",
    "    alignment_file = f\"../results/{subtype}/{segment}/aligned.fasta\"\n",
    "    output_tree_file = f\"../results/{subtype}/{segment}/tree_raw.nwk\"\n",
    "    \n",
    "    # Construct the augur tree command\n",
    "    command = [\n",
    "        \"augur\", \"tree\",\n",
    "        \"--alignment\", alignment_file,\n",
    "        \"--output\", output_tree_file\n",
    "    ]\n",
    "    \n",
    "    # Run the command and capture the result\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Print the result and indicate the segment processing status\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Successfully aligned {segment} for subtype {subtype}. Tree saved to {output_tree_file}\")\n",
    "    else:\n",
    "        print(f\"Failed to align {segment} for subtype {subtype}. Error: {result.stderr}\")\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        print(f\"Processing alignment for {segment} in subtype {subtype}...\")\n",
    "        build_raw_tree(subtype, segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## refine\n",
    "\n",
    "need to first add the date column to the original metadata parsed from the raw data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining tree for vic/mp...\n",
      "Completed refining tree for vic/mp\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \n",
    "}\n",
    "\n",
    "def refine_tree(subtype, segment):\n",
    "    tree_file = f\"../results/{subtype}/{segment}/tree_raw.nwk\"\n",
    "    alignment_file = f\"../results/{subtype}/{segment}/aligned.fasta\"\n",
    "    metadata_file = f\"../results/{subtype}/{segment}/filtered.tsv\"\n",
    "    output_tree_file = f\"../results/{subtype}/{segment}/tree.nwk\"\n",
    "    output_node_data_file = f\"../results/{subtype}/{segment}/branch_lengths.json\"\n",
    "    \n",
    "    # Construct the augur refine command\n",
    "    command = [\n",
    "        \"augur\", \"refine\",\n",
    "        \"--tree\", tree_file,\n",
    "        \"--alignment\", alignment_file,\n",
    "        \"--metadata\", metadata_file,\n",
    "        \"--output-tree\", output_tree_file,\n",
    "        \"--output-node-data\", output_node_data_file,\n",
    "        \"--timetree\",\n",
    "        \"--coalescent\", \"opt\",\n",
    "        \"--date-confidence\",\n",
    "        \"--date-inference\", \"marginal\",\n",
    "        \"--clock-filter-iqd\", \"4\" # removes tips that deviate more than n_iqd interquartile ranges from the root-to-tip vs time regression.\n",
    "    ]\n",
    "    # Add --clock-rate argument only for vic subtype and PB2, NP segments. These are taken from the bedford lab 60yr vic build: \n",
    "    # https://nextstrain.org/groups/blab/flu/seasonal/vic/np/60y?l=clock\n",
    "\n",
    "    if subtype == \"vic\" and segment == \"pb2\":\n",
    "        command.extend([\"--clock-rate\", \"0.00108\"])\n",
    "    if subtype == \"vic\" and segment == \"np\":\n",
    "        command.extend([\"--clock-rate\", \"0.00134\"])\n",
    "    if subtype == \"vic\" and segment == \"na\":\n",
    "        command.extend([\"--clock-rate\", \"0.00133\"])\n",
    "    if subtype == \"h3n2\" and segment == \"pb2\":\n",
    "        command.extend([\"--clock-rate\", \"0.00218\"])\n",
    "    \n",
    "    # Print progress message\n",
    "    print(f\"Refining tree for {subtype}/{segment}...\")\n",
    "    \n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error refining tree for {subtype}/{segment}:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(f\"Completed refining tree for {subtype}/{segment}\")\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        refine_tree(subtype, segment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## annotate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augur traits \\\n",
    "  --tree ../results/{subtype}/{segment}/tree_raw.nwk \\\n",
    "  --metadata ../results/{subtype}/{segment}/filtered.tsv  \\\n",
    "  --output-node-data ../results/{subtype}/{segment}/traits.json \\\n",
    "  --columns clade subclade qc_overallStatus qc_overallScore coverage sequencing_run \\\n",
    "  --confidence\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotating traits for vic/mp...\n",
      "Completed annotating traits for vic/mp\n",
      "Total execution time: 4.98 seconds\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def annotate_traits(subtype, segment):\n",
    "    tree_file = f\"../results/{subtype}/{segment}/tree.nwk\"\n",
    "    metadata_file = f\"../results/{subtype}/{segment}/filtered.tsv\"\n",
    "    output_node_data_file = f\"../results/{subtype}/{segment}/traits.json\"\n",
    "    \n",
    "    # Construct the augur traits command\n",
    "    command = [\n",
    "        \"augur\", \"traits\",\n",
    "        \"--tree\", tree_file,\n",
    "        \"--metadata\", metadata_file,\n",
    "        \"--output-node-data\", output_node_data_file,\n",
    "        \"--columns\", \"clade\", \"subclade\", \"qc_overallStatus\", \"qc_overallScore\", \"coverage\", \"sequencing_run\",\n",
    "        \"--confidence\"\n",
    "    ]\n",
    "    \n",
    "    # Print progress message\n",
    "    print(f\"Annotating traits for {subtype}/{segment}...\")\n",
    "    \n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error annotating traits for {subtype}/{segment}:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(f\"Completed annotating traits for {subtype}/{segment}\")\n",
    "\n",
    "# Timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        annotate_traits(subtype, segment)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Total execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer ancestral sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running augur ancestral for vic/mp...\n",
      "Completed augur ancestral for vic/mp\n",
      "Total execution time: 1.67 seconds\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def run_augur_ancestral(subtype, segment):\n",
    "    tree_file = f\"../results/{subtype}/{segment}/tree.nwk\"\n",
    "    alignment_file = f\"../results/{subtype}/{segment}/aligned.fasta\"\n",
    "    output_node_data = f\"../results/{subtype}/{segment}/nt_muts.json\"\n",
    "    \n",
    "    # Augur ancestral command\n",
    "    command = [\n",
    "        \"augur\", \"ancestral\",\n",
    "        \"--tree\", tree_file,\n",
    "        \"--alignment\", alignment_file,\n",
    "        \"--output-node-data\", output_node_data,\n",
    "        \"--inference\", \"joint\"\n",
    "    ]\n",
    "    \n",
    "    # Print progress message\n",
    "    print(f\"Running augur ancestral for {subtype}/{segment}...\")\n",
    "    \n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error running augur ancestral for {subtype}/{segment}:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(f\"Completed augur ancestral for {subtype}/{segment}\")\n",
    "\n",
    "# Timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        run_augur_ancestral(subtype, segment)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Total execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## translate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating sequences for vic/mp...\n",
      "stdout for vic/mp:\n",
      "Read in 3 features from reference sequence file\n",
      "Validating schema of '../results/vic/mp/nt_muts.json'...\n",
      "Validating schema of '../results/vic/mp/aa_muts.json'...\n",
      "amino acid mutations written to ../results/vic/mp/aa_muts.json\n",
      "\n",
      "Total execution time: 1.62 seconds\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def translate_sequences(subtype, segment):\n",
    "    tree_file = f\"../results/{subtype}/{segment}/tree.nwk\"\n",
    "    ancestral_sequences_file = f\"../results/{subtype}/{segment}/nt_muts.json\"\n",
    "    reference_sequence_file_ha = f\"../config/{subtype}/genome_annotation_ha.gff\"\n",
    "    reference_sequence_file = f\"../config/{subtype}/reference_{segment}.gb\"\n",
    "    output_node_data_file = f\"../results/{subtype}/{segment}/aa_muts.json\"\n",
    "    \n",
    "    # Use the .gff file for the HA segment and the .gb file for all other segments\n",
    "    if segment == \"ha\":\n",
    "        reference_sequence_file = reference_sequence_file_ha\n",
    "    \n",
    "    # Construct the augur translate command\n",
    "    command = [\n",
    "        \"augur\", \"translate\",\n",
    "        \"--tree\", tree_file,\n",
    "        \"--ancestral-sequences\", ancestral_sequences_file,\n",
    "        \"--reference-sequence\", reference_sequence_file,\n",
    "        \"--output-node-data\", output_node_data_file\n",
    "    ]\n",
    "    \n",
    "    # Print progress message\n",
    "    print(f\"Translating sequences for {subtype}/{segment}...\")\n",
    "    \n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Output the result\n",
    "    print(f\"stdout for {subtype}/{segment}:\\n{result.stdout}\")\n",
    "    if result.stderr:\n",
    "        print(f\"stderr for {subtype}/{segment}:\\n{result.stderr}\")\n",
    "\n",
    "# Timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        translate_sequences(subtype, segment)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Total execution time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export auspice v2 json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting build for h3n2/pb2...\n",
      "Completed exporting build for h3n2/pb2\n",
      "Exporting build for h3n2/pb1...\n",
      "Completed exporting build for h3n2/pb1\n",
      "Exporting build for h3n2/pa...\n",
      "Completed exporting build for h3n2/pa\n",
      "Exporting build for h3n2/ha...\n",
      "Completed exporting build for h3n2/ha\n",
      "Exporting build for h3n2/np...\n",
      "Completed exporting build for h3n2/np\n",
      "Exporting build for h3n2/na...\n",
      "Completed exporting build for h3n2/na\n",
      "Exporting build for h3n2/mp...\n",
      "Completed exporting build for h3n2/mp\n",
      "Exporting build for h3n2/ns...\n",
      "Completed exporting build for h3n2/ns\n",
      "Exporting build for h1n1/pb2...\n",
      "Completed exporting build for h1n1/pb2\n",
      "Exporting build for h1n1/pb1...\n",
      "Completed exporting build for h1n1/pb1\n",
      "Exporting build for h1n1/pa...\n",
      "Completed exporting build for h1n1/pa\n",
      "Exporting build for h1n1/ha...\n",
      "Completed exporting build for h1n1/ha\n",
      "Exporting build for h1n1/np...\n",
      "Completed exporting build for h1n1/np\n",
      "Exporting build for h1n1/na...\n",
      "Completed exporting build for h1n1/na\n",
      "Exporting build for h1n1/mp...\n",
      "Completed exporting build for h1n1/mp\n",
      "Exporting build for h1n1/ns...\n",
      "Completed exporting build for h1n1/ns\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def export_build(subtype, segment):\n",
    "    tree_file = f\"../results/{subtype}/{segment}/tree.nwk\"\n",
    "    metadata_file = f\"../results/{subtype}/{segment}/filtered.tsv\"\n",
    "    node_data_files = [\n",
    "        f\"../results/{subtype}/{segment}/branch_lengths.json\",\n",
    "        f\"../results/{subtype}/{segment}/traits.json\",\n",
    "        f\"../results/{subtype}/{segment}/nt_muts.json\",\n",
    "        f\"../results/{subtype}/{segment}/aa_muts.json\",\n",
    "        f\"../config/{subtype}/vaccine.json\" # add updated vaccine strains here.\n",
    "    ]\n",
    "    auspice_config_file = f\"../config/{subtype}/auspice_config.json\"\n",
    "    output_file = f\"../auspice/{subtype}/{segment}.json\"\n",
    "    \n",
    "    # Ensure output directory exists, create if not\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct the augur export command\n",
    "    command = [\n",
    "        \"augur\", \"export\", \"v2\",\n",
    "        \"--tree\", tree_file,\n",
    "        \"--metadata\", metadata_file,\n",
    "        \"--node-data\"\n",
    "    ]\n",
    "    command.extend(node_data_files)\n",
    "    command.extend([\n",
    "        \"--auspice-config\", auspice_config_file,\n",
    "        \"--output\", output_file\n",
    "    ])\n",
    "    \n",
    "    print(f\"Exporting build for {subtype}/{segment}...\")\n",
    "    \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error exporting build for {subtype}/{segment}:\")\n",
    "        print(result.stderr)\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"Completed exporting build for {subtype}/{segment}\")\n",
    "\n",
    "# Loop through each subtype and segment\n",
    "for subtype, segments in subtypes.items():\n",
    "    for segment in segments:\n",
    "        export_build(subtype, segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading builds to Private Nextstrain Instance\n",
    "\n",
    "build names:\n",
    "- \"title\": \"Baltimore 2023-24 season influenza A/H1N1pdm evolution\"\n",
    "- \"title\": \"Baltimore 2023-24 season influenza B/Vic evolution\"\n",
    "- \"title\": \"Baltimore 2023-24 season influenza A/H3N2 evolution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in to Nextstrain...\n",
      "Successfully logged in to Nextstrain\n",
      "Uploading data for h3n2 to Nextstrain...\n",
      "Successfully uploaded data for h3n2\n",
      "Uploading data for h1n1 to Nextstrain...\n",
      "Successfully uploaded data for h1n1\n",
      "Uploading data for vic to Nextstrain...\n",
      "Successfully uploaded data for vic\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def nextstrain_login():\n",
    "    # Log in to Nextstrain CLI\n",
    "    print(\"Logging in to Nextstrain...\")\n",
    "    result = subprocess.run([\"nextstrain\", \"login\"], capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error logging in to Nextstrain:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(\"Successfully logged in to Nextstrain\")\n",
    "\n",
    "def nextstrain_upload(subtype):\n",
    "    # Construct the nextstrain remote upload command\n",
    "    command = [\n",
    "        \"nextstrain\", \"remote\", \"upload\",\n",
    "        f\"nextstrain.org/groups/PekoszLab/{subtype}\"\n",
    "    ] + [f\"../auspice/{subtype}/{segment}.json\" for segment in subtypes[subtype]]\n",
    "    \n",
    "    # Print progress message\n",
    "    print(f\"Uploading data for {subtype} to Nextstrain...\")\n",
    "    \n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error uploading data for {subtype}:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(f\"Successfully uploaded data for {subtype}\")\n",
    "\n",
    "# Log in to Nextstrain CLI\n",
    "nextstrain_login()\n",
    "\n",
    "# Upload data for each subtype\n",
    "for subtype in subtypes.keys():\n",
    "    nextstrain_upload(subtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Public Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in to Nextstrain...\n",
      "Successfully logged in to Nextstrain\n",
      "Uploading data for h3n2 to Nextstrain...\n",
      "Successfully uploaded data for h3n2\n",
      "Uploading data for h1n1 to Nextstrain...\n",
      "Successfully uploaded data for h1n1\n",
      "Uploading data for vic to Nextstrain...\n",
      "Successfully uploaded data for vic\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the subtypes and their segments\n",
    "subtypes = {\n",
    "    \"h3n2\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"h1n1\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"],\n",
    "    \"vic\": [\"pb2\", \"pb1\", \"pa\", \"ha\", \"np\", \"na\", \"mp\", \"ns\"]\n",
    "}\n",
    "\n",
    "def nextstrain_login():\n",
    "    # Log in to Nextstrain CLI\n",
    "    print(\"Logging in to Nextstrain...\")\n",
    "    result = subprocess.run([\"nextstrain\", \"login\"], capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error logging in to Nextstrain:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(\"Successfully logged in to Nextstrain\")\n",
    "\n",
    "def nextstrain_upload(subtype):\n",
    "    # Construct the nextstrain remote upload command\n",
    "    command = [\n",
    "        \"nextstrain\", \"remote\", \"upload\",\n",
    "        f\"nextstrain.org/groups/PekoszLab-Public/{subtype}\"\n",
    "    ] + [f\"../auspice/{subtype}/{segment}.json\" for segment in subtypes[subtype]]\n",
    "    \n",
    "    # Print progress message\n",
    "    print(f\"Uploading data for {subtype} to Nextstrain...\")\n",
    "    \n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error uploading data for {subtype}:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(f\"Successfully uploaded data for {subtype}\")\n",
    "\n",
    "# Log in to Nextstrain CLI\n",
    "nextstrain_login()\n",
    "\n",
    "# Upload data for each subtype\n",
    "for subtype in subtypes.keys():\n",
    "    nextstrain_upload(subtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
